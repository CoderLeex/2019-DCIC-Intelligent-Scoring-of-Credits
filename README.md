# 2019-DCIC-Intelligent-Scoring-of-Credits
# 消费者人群画像—信用智能评分赛后总结

### 写在前面
研一下半学期刚好有时间就和室友一起参加了这次比赛。本身都是学图像的，第一次搞数据挖掘，一边摸索讨论一边实践，摸爬滚打的踩过了各种坑，可以说从中成长了不少，比赛刚结束趁热记录下，有理解不对的地方也希望指出，非常感谢。<br><br>比赛中也深深感到自己水平的有限，无论是理论知识，编程水平，思维逻辑还是各种比赛中的调参和骚操作都很缺乏，特别是比赛后半段很乏力，b榜的时候感觉到经验和能力的不足，之后需要认真研究下大佬的开源。<br><br>
有些想法想到却也没有很好的尝试，生活是残缺的艺术，希望之后比赛能解决这些问题，加油。


### 简介
  - [赛题介绍](https://www.datafountain.cn/competitions/337/details/rule)
  - A榜：**8/2278** 成绩：0.06412157
  - B榜：**8/2278** 成绩：0.06399675
  - Model：LightGBM CatBoost XgBoost
  - 注：开源部分为本人和室友的部分，A榜线上成绩：0.064098

### EDA

 - EDA使用jupyter跑很直观，但这一块感觉自己还没get到精髓，有时间再写吧

### 特征工程

  - 通过数据间业务关联分析，进行缴费数据修正处理

    > 通过缴费用户最近一次缴费金额（元）修正 用户最近一次缴费距今时长（月），并结合相关性对两个特征进行分箱
    >
    > - 分三类，未缴费=0，缴费但充值金额=1，其他为-1
    > - 可能是充值金额为1为官方某种活动
    
    > 通过充值金额判断充值方式
    >
    > - 通过充值金额分三类，充值金额=0，充值金额能被10整除，充值金额不能被10整除
    > - 尝试编码后进行One-Hot，效果不好
 
  - 题目中特征，我感觉官方所有缺失值都自动补了0（这个是最坑的，个人认为这是这题很难做特征的直接原因，也不知道还有没有强行把数据搞坏的操作），对部分特征缺失值还原为NaN

    > 缴费用户最近一次缴费金额（元）
    >
    > 用户年龄
    >
    > 用户话费敏感度
    >
    > 同时尝试了对缺失值进行各种方法的填充，效果都不好，保留了NaN
    > - 中位数、众数、平均数
    > - 使用模型训练出预测值进行填充等

  - Boolean型特征二次组合，比如可能是否大学生+是否黑名单时才是强特

    > 暴力跑了600维的特征进行筛选，通过特征重要性和PCA降维来筛选效果都不是很好，通过业务逻辑筛选出两个特征 ，并对偏好进行One-hot编码
    
    ```python
    #是否去过高档商场   
    df['是否去过高档商场']=df['当月是否到过福州山姆会员店']+df['当月是否逛过福州仓山万达']
    df['是否去过高档商场']=df['是否去过高档商场'].map(lambda x:1 if x>=1 else 0) 
    #交通类应用使用次数
    df['交通类应用使用次数'] = df['当月飞机类应用使用次数'] + df['当月火车类应用使用次数']
    #app偏好
    df["偏好"]=0
    df["偏好"][(df["当月网购类应用使用次数"]>df['当月金融理财类应用使用总次数'])&(df['当月网购类应用使用次数']>df['当月视频播放类应用使用次数'])]=1
    df["偏好"][(df["当月金融理财类应用使用总次数"]>df['当月网购类应用使用次数'])&(df['当月金融理财类应用使用总次数']>df['当月视频播放类应用使用次数'])]=2
    df = pd.get_dummies(df, columns=["偏好"])
    #drop掉原始特征
    df=df.drop({'当月是否逛过福州仓山万达','当月是否到过福州山姆会员店'},axis=1)
    df=df.drop({'当月火车类应用使用次数','当月飞机类应用使用次数'},axis=1)
    ```
    
  - 用户近6个月平均消费值（元）和用户账单当月总费用（元）之比，判断消费方式是否发生变化

    > 超级强特
    >
    > 将六月话费变为前五个月的，减小特征相关性

  - drop掉原始特征减小特征相关度

    ```python
    #drop  
    df=df.drop({'当月是否逛过福州仓山万达','当月是否到过福州山姆会员店'},axis=1)
    df=df.drop({"用户近6个月平均消费值（元）"},axis=1)
    df=df.drop({'用户最近一次缴费距今时长（月）'},axis=1)
    df=df.drop({'当月火车类应用使用次数','当月飞机类应用使用次数'},axis=1)
    ```
    
  - 数据处理，对首尾异常值进行了处理，并对次数特征取了log

    - 尝试在做特征前处理数据，但效果不好，选择在特征做完后处理
    - 将首位异常值处理成0.1%和99.9%的数值
    - 按理来说树模型不用进行log处理，但实际有一定作用，可能是对树模型筛选特征有影响

  - 尝试过的特征

    - 太多了- -，这题很怪，基本都没用
    - 将lgb的特征/10丢入xgb学习，可能能学到更多东西？
    - 其他尝试使用的特征，放在history里

### 模型融合

  - 基模型
    - lightgbm，使用了mae和mse两种
    - xgboost，将lgb特征/10作为特征丢入xgb学习(国强)
    - catboost，速度很慢，但融合效果非常好

  - stacking融合
    - 使用BayesianRidge、 LinearRegression作为融合模型都试过
    - 效果很差，问了群里很多人也有相似情况，个人感觉是数据缺陷较大，stacking学习能力过强，学到的权重对训练集过拟合了（但数据本身有毛病），也可能是自己使用姿势不对...
    
  - 加权融合
    - 效果很好，融合上分非常多，主要还是堆模型，做了三套特征，九个模型进行融合
    - 权重设置过很多种，最后发现还是平均好 - -！

  - 其他尝试
    - 通过分析发现树模型对分值偏低的预测的很差，对其他的预测的都非常好，感觉这是个切入口，但没发现什么好的处理方式
    - 发现数据普遍偏小，但只对预测值进行了简单的右移操作，效果出奇的好（这算是骚操作吗...）
    - 尝试融合时对score进行排序，对分值偏低的加大catboost、xgb和lgb_mse的权重，这三个模型都使用l1评价标准，对极值预测比较大，实践发现能提高一点分数
    - 适当提高模型折数，融合多个种子，消除随机性，有良好的提升
    - 顺便提醒下自己，下个比赛一定要暴力跑种子！找到magic！

### 主要文件说明
**数据清洗预处理以及特征工程文件：**
- `feature_engineering_chai.py`：特征压缩版
- `feature_engineering_gavin.py`：多特征版
- `feature_engineering_wolf.py`：修改自wolfkin<br><br>
**训练及预测：**
- `model_chai.py`：特征压缩版
- `model_gavin.py`：多特征版
- `model_wolf.py`：修改自wolfkin<br><br>
**融合(stacking和加权)：**
- `stacking.py`<br><br>
**调参代码：**
- `search_mae.py`
- `search_mse.py`
- `search_xgb.py`

### 不足与思考：
**由于缺乏比赛经验，在整个比赛的过程中有很多欠缺的地方**
- 在特征筛选上没太多经验，对线上线下不一致的情况很头疼，参考lgb输出的特征重要性对这题几乎无效，很多得分很高的特征都掉分（网上看到一个比较好的特征选择方法是，每次构造的特征计算其在训练集和测试集上的均值和方差，保证分布相同，差不多则放入模型训练，如果结果比之前好那这个特征就基本可用，但实践中发现效果也不是太好），只能做参考，对于这点需要好好借鉴大佬经验，
- 做特征还是有很多方法自己不了解，需要多多了解。
- 数据处理不太行，前面有提到，对数据有些敏感性，但经验还是不足吧
- 调参也需要提高，对模型深层理解还不够，这次比赛比较特殊，调参代码都是自己写的，赛后了解到很多很优秀的包可以使用，可以研究下，提升下自己调参的效率，而且感觉自己参数也没调到很优，模型潜力还有（个人感觉）
- 不过总体来说作为第一次比赛结果还是不错的，在这里非常感谢一起奋斗过来的自己的室友兼战友老柴，实验室的师兄，国强，梦真，dyj，以及github开源的大佬(特别是wolfkin-hth、Venn和luoling1993，代码写得很优秀，学到很多)，以及群里帮助解答疑惑的前辈。

### 参考资料（再次说声感谢！）
  - [wolfkin-hth开源](https://github.com/wolfkin-hth/ImageOfConsumers)wolfkin-hth的开源也是我们使用的框架
  - [luoling1993开源](https://github.com/luoling1993/DataFountain-Intelligent-Credit-Score/blob/master/README.md) 
  - [Venn开源](https://github.com/wangvenn/Credit-Scoring-Regression) 
  
